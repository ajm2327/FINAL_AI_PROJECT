{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "\n",
        "1. load csv file (panda, numpy)\n",
        "2. split dataset. Example code:()\n",
        "   ```\n",
        "   random.shuffle(data) # change if you are using pandas dataframe\n",
        "   training = data[:int(len(data)*0.8)]\n",
        "   test = data[int(len(data)*0.8):]\n",
        "\n",
        "   fold5 = KFold(5) # https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
        "   for train_idx, val_idx in fold5.split(training):\n",
        "      sub_val = training[val_idx]\n",
        "      sub_train = training[train_idx]\n",
        "      clf = model(sub_train, sub_val, ...) # training the model, and evaluate it on validation dataset\n",
        "      performance(clf, test) # test the model on test dataset\n",
        "   ```"
      ],
      "metadata": {
        "id": "uxgBX0YXu1du"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPROCESS *DATASET*"
      ],
      "metadata": {
        "id": "tmH_3IdORbaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('spambase.csv')\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing values:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Handle missing values (if any)\n",
        "data.dropna(inplace=True)  # Remove rows with missing values\n",
        "\n",
        "# Scale the features using Min-Max scaling\n",
        "scaler = MinMaxScaler()\n",
        "scaled_features = scaler.fit_transform(data.drop(columns=['spam']))\n",
        "scaled_data = pd.DataFrame(scaled_features, columns=data.columns[:-1])\n",
        "scaled_data['spam'] = data['spam']\n",
        "\n",
        "# Handle imbalanced data (if necessary)\n",
        "# You can use techniques like oversampling or undersampling here\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X = scaled_data.drop(columns=['spam'])\n",
        "y = scaled_data['spam']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for train_index, val_index in kfold.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "    # Train and evaluate models for each fold\n",
        "    # Implement your models here\n",
        "\n",
        "# Save the preprocessed data\n",
        "scaled_data.to_csv('preprocessed_email_spam_dataset.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdzsE6MVRQ6q",
        "outputId": "ea1d3c8c-c956-418a-f270-e53748bb4bd3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values:\n",
            "word_freq_make                0\n",
            "word_freq_address             0\n",
            "word_freq_all                 0\n",
            "word_freq_3d                  0\n",
            "word_freq_our                 0\n",
            "word_freq_over                0\n",
            "word_freq_remove              0\n",
            "word_freq_internet            0\n",
            "word_freq_order               0\n",
            "word_freq_mail                0\n",
            "word_freq_receive             0\n",
            "word_freq_will                0\n",
            "word_freq_people              0\n",
            "word_freq_report              0\n",
            "word_freq_addresses           0\n",
            "word_freq_free                0\n",
            "word_freq_business            0\n",
            "word_freq_email               0\n",
            "word_freq_you                 0\n",
            "word_freq_credit              0\n",
            "word_freq_your                0\n",
            "word_freq_font                0\n",
            "word_freq_000                 0\n",
            "word_freq_money               0\n",
            "word_freq_hp                  0\n",
            "word_freq_hpl                 0\n",
            "word_freq_george              0\n",
            "word_freq_650                 0\n",
            "word_freq_lab                 0\n",
            "word_freq_labs                0\n",
            "word_freq_telnet              0\n",
            "word_freq_857                 0\n",
            "word_freq_data                0\n",
            "word_freq_415                 0\n",
            "word_freq_85                  0\n",
            "word_freq_technology          0\n",
            "word_freq_1999                0\n",
            "word_freq_parts               0\n",
            "word_freq_pm                  0\n",
            "word_freq_direct              0\n",
            "word_freq_cs                  0\n",
            "word_freq_meeting             0\n",
            "word_freq_original            0\n",
            "word_freq_project             0\n",
            "word_freq_re                  0\n",
            "word_freq_edu                 0\n",
            "word_freq_table               0\n",
            "word_freq_conference          0\n",
            "char_freq_;                   0\n",
            "char_freq_(                   0\n",
            "char_freq_[                   0\n",
            "char_freq_!                   0\n",
            "char_freq_$                   0\n",
            "char_freq_#                   0\n",
            "capital_run_length_average    0\n",
            "capital_run_length_longest    0\n",
            "capital_run_length_total      0\n",
            "spam                          0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATE TEST SET, TRAINING SET"
      ],
      "metadata": {
        "id": "GJTEAchkRmhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv('preprocessed_email_spam_dataset.csv')\n",
        "\n",
        "# Split the dataset into features and target variable\n",
        "X = preprocessed_data.drop(columns=['spam'])  # Features\n",
        "y = preprocessed_data['spam']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of the training and testing sets\n",
        "print(\"Training set shape:\")\n",
        "print(\"Features:\", X_train.shape)\n",
        "print(\"Target:\", y_train.shape)\n",
        "\n",
        "print(\"\\nTesting set shape:\")\n",
        "print(\"Features:\", X_test.shape)\n",
        "print(\"Target:\", y_test.shape)\n",
        "\n",
        "# Save the training and testing sets to separate CSV files\n",
        "X_train.to_csv('X_train.csv', index=False)\n",
        "y_train.to_csv('y_train.csv', index=False)\n",
        "X_test.to_csv('X_test.csv', index=False)\n",
        "y_test.to_csv('y_test.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfPo3E8BRp52",
        "outputId": "6acabac6-b9a7-47d2-fde6-37ac10e3f3d8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape:\n",
            "Features: (3680, 57)\n",
            "Target: (3680,)\n",
            "\n",
            "Testing set shape:\n",
            "Features: (921, 57)\n",
            "Target: (921,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Naive bayes\n",
        "\n",
        "1. model learning:\n",
        "\n",
        "   Note:\n",
        "\n",
        "   features: remove attributes that is not related to word (the last four attributes)\n",
        "\n",
        "   labels: the last column\n",
        "\n",
        "   count P(c) -> how many samples are positive, and how many are negtive\n",
        "\n",
        "   if freq_word>0, then this word exists. You could use this to calculate P(a|c) -> for each class, what is the prob of each word\n",
        "\n",
        "   remember to use laplace smoothing.\n",
        "\n",
        "2. model evaluation (on val dataset -> performance(model, val)):\n",
        "   \n",
        "   for each new sample, $\\prod{P(a|c)}P(c)$ if word is in the email(freq_word > 0); and find the maximum class\n",
        "   \n",
        "\n",
        "   "
      ],
      "metadata": {
        "id": "FXyRfd35yRPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NAIVE BAYES"
      ],
      "metadata": {
        "id": "f-PjcvORRsm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the training data\n",
        "X_train = pd.read_csv('X_train.csv')\n",
        "y_train = pd.read_csv('y_train.csv', header=None, names=['spam'], skiprows=1)\n",
        "\n",
        "# Calculate the prior probabilities\n",
        "spam_count = y_train['spam'].sum()\n",
        "not_spam_count = len(y_train) - spam_count\n",
        "p_spam = spam_count / len(y_train)\n",
        "p_not_spam = not_spam_count / len(y_train)\n",
        "\n",
        "# Calculate the conditional probabilities for each feature\n",
        "spam_feature_probs = {}\n",
        "not_spam_feature_probs = {}\n",
        "\n",
        "for column in X_train.columns:\n",
        "    spam_feature_count = X_train[column][y_train['spam'] == 1].sum()\n",
        "    not_spam_feature_count = X_train[column][y_train['spam'] == 0].sum()\n",
        "    spam_feature_probs[column] = (spam_feature_count + 1) / (spam_count + 2)\n",
        "    not_spam_feature_probs[column] = (not_spam_feature_count + 1) / (not_spam_count + 2)\n",
        "\n",
        "# Function to predict the class of an email\n",
        "def predict_email(email_features):\n",
        "    spam_prob = np.log(p_spam)\n",
        "    not_spam_prob = np.log(p_not_spam)\n",
        "\n",
        "    for column in X_train.columns:\n",
        "        if email_features[column] == 1:\n",
        "            spam_prob += np.log(spam_feature_probs[column])\n",
        "            not_spam_prob += np.log(not_spam_feature_probs[column])\n",
        "\n",
        "    if spam_prob > not_spam_prob:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Load the testing data\n",
        "X_test = pd.read_csv('X_test.csv')\n",
        "y_test = pd.read_csv('y_test.csv', header=None, names=['spam'], skiprows=1)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = X_test.apply(predict_email, axis=1)\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print the performance metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeG1FtFwR0Mp",
        "outputId": "af9c4991-8f72-46a2-c904-b713ed3dbf65"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5830618892508144\n",
            "Precision: 1.0\n",
            "Recall: 0.015384615384615385\n",
            "F1-score: 0.030303030303030307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN\n",
        "1. model learning: None\n",
        "\n",
        "2. model evaluation(on val dataset): You could use each row(exclude the last column) as the feature of the email. You do not have to recalcuate the freqency.\n",
        "\n",
        "   ```\n",
        "   Note:\n",
        "   parallel programing\n",
        "   numpy.cos() to calcuate the similarity\n",
        "   ```"
      ],
      "metadata": {
        "id": "5jRvHTlW0DYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the training data\n",
        "X_train = pd.read_csv('X_train.csv')\n",
        "y_train = pd.read_csv('y_train.csv', header=None, names=['spam'], skiprows=1)\n",
        "\n",
        "# Load the testing data\n",
        "X_test = pd.read_csv('X_test.csv')\n",
        "y_test = pd.read_csv('y_test.csv', header=None, names=['spam'], skiprows=1)\n",
        "\n",
        "# Create a KNN classifier class\n",
        "class KNNClassifier:\n",
        "    def __init__(self, n_neighbors=5):\n",
        "        self.n_neighbors = n_neighbors\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        distances = np.sqrt(np.sum((self.X_train.values[:, np.newaxis] - X.values)**2, axis=2))\n",
        "        indices = np.argsort(distances, axis=0)[:self.n_neighbors]\n",
        "        nearest_labels = self.y_train.values[indices]\n",
        "        y_pred = np.apply_along_axis(lambda x: np.argmax(np.bincount(x)), axis=0, arr=nearest_labels)\n",
        "        return y_pred\n",
        "\n",
        "# Create a KNN classifier instance\n",
        "k = 5  # Number of neighbors\n",
        "knn = KNNClassifier(n_neighbors=k)\n",
        "\n",
        "# Perform 5-fold cross-validation on the training data\n",
        "num_folds = 5\n",
        "fold_size = len(X_train) // num_folds\n",
        "cv_scores = []\n",
        "for i in range(num_folds):\n",
        "    start = i * fold_size\n",
        "    end = start + fold_size\n",
        "    X_val_fold = X_train.iloc[start:end]\n",
        "    y_val_fold = y_train.iloc[start:end]\n",
        "    X_train_fold = pd.concat([X_train.iloc[:start], X_train.iloc[end:]])\n",
        "    y_train_fold = pd.concat([y_train.iloc[:start], y_train.iloc[end:]])\n",
        "    knn.fit(X_train_fold, y_train_fold)\n",
        "    y_pred_fold = knn.predict(X_val_fold)\n",
        "    cv_scores.append(accuracy_score(y_val_fold, y_pred_fold))\n",
        "\n",
        "# Print the cross-validation scores\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean cross-validation score:\", np.mean(cv_scores))\n",
        "\n",
        "# Train the KNN classifier on the entire training set\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print the performance metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB53pmCeTTT7",
        "outputId": "f1dc5616-671f-4cf7-d45a-11815231c91d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.8953804347826086, 0.8872282608695652, 0.8913043478260869, 0.9171195652173914, 0.9089673913043478]\n",
            "Mean cross-validation score: 0.9\n",
            "Accuracy: 0.8838219326818675\n",
            "Precision: 0.8773333333333333\n",
            "Recall: 0.8435897435897436\n",
            "F1-score: 0.8601307189542484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LR\n",
        "\n",
        "1. model learning: You could use each row(exclude the last column) as the feature of the email. You do not have to recalcuate the freqency.\n",
        "    \n",
        "    $y = sigmoid(MX)$\n",
        "\n",
        "step 1: add one more column (all value is 1) in X -> X' = np.c_[np.ones((len(X), 1)), X]\n",
        "\n",
        "step 2:vector M = np.random.randn(len(X[0])+1, 1);\n",
        "\n",
        "key formula for step 3 (Note: n is the size of the TRAINING dataset; $cdot$ is dot production ):\n",
        "\n",
        "1. $pred_y = sigmoid(M\\cdot X')$\n",
        "\n",
        "2. $loss = -\\sum(y\\cdot log(pred_y)+(1-y)\\cdot log(1-pred_y))/n$\n",
        "\n",
        "3. $gm=X'\\cdot (pred_y - y)*2/n$\n",
        "\n",
        "Step 3 example code:\n",
        "   ```\n",
        "   #Step 3: performing gradient descent on whole dataset:\n",
        "   best_model = M\n",
        "   best_performace = 0\n",
        "   for i in range(epoch):\n",
        "     pred_y = ...\n",
        "     gm = ...\n",
        "     _p = performace(model, val)\n",
        "     if _p > best_performance:\n",
        "        best_model = M\n",
        "        best_performance = _p\n",
        "     M = M - learning_rate*gm\n",
        "   ```\n",
        "\n",
        "2. model evaluation(on val dataset):\n",
        "  \n",
        "   calculate pred_y, if more than 0.5, then the predicted label is 1."
      ],
      "metadata": {
        "id": "OUzUupva0Fxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the training data\n",
        "X_train = pd.read_csv('X_train.csv').values\n",
        "y_train = pd.read_csv('y_train.csv', header=None, names=['spam'], skiprows=1).values.ravel()\n",
        "\n",
        "# Load the validation data\n",
        "X_val = pd.read_csv('X_test.csv').values\n",
        "y_val = pd.read_csv('y_test.csv', header=None, names=['spam'], skiprows=1).values.ravel()\n",
        "\n",
        "# Add a column of ones to X_train and X_val\n",
        "X_train = np.c_[np.ones((len(X_train), 1)), X_train]\n",
        "X_val = np.c_[np.ones((len(X_val), 1)), X_val]\n",
        "\n",
        "# Initialize the model parameters\n",
        "M = np.random.randn(X_train.shape[1], 1)\n",
        "\n",
        "# Sigmoid function\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# Performance evaluation function\n",
        "def performance(model, X, y):\n",
        "    pred_y = sigmoid(np.dot(X, model))\n",
        "    pred_labels = (pred_y > 0.5).astype(int)\n",
        "    accuracy = accuracy_score(y, pred_labels)\n",
        "    precision = precision_score(y, pred_labels)\n",
        "    recall = recall_score(y, pred_labels)\n",
        "    f1 = f1_score(y, pred_labels)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.01\n",
        "epoch = 100\n",
        "\n",
        "# Training loop\n",
        "best_model = M\n",
        "best_performance = 0\n",
        "for i in range(epoch):\n",
        "    # Forward pass\n",
        "    pred_y = sigmoid(np.dot(X_train, M))\n",
        "\n",
        "    # Compute loss\n",
        "    loss = -np.sum(y_train * np.log(pred_y) + (1 - y_train) * np.log(1 - pred_y)) / len(X_train)\n",
        "\n",
        "    # Compute gradient\n",
        "    gm = np.dot(X_train.T, (pred_y - y_train.reshape(-1, 1))) * 2 / len(X_train)\n",
        "\n",
        "    # Evaluate performance on validation set\n",
        "    _accuracy, _precision, _recall, _f1 = performance(M, X_val, y_val)\n",
        "    _p = _f1  # You can choose any metric as the performance measure\n",
        "\n",
        "    if _p > best_performance:\n",
        "        best_model = M\n",
        "        best_performance = _p\n",
        "\n",
        "    # Update model parameters\n",
        "    M = M - learning_rate * gm\n",
        "\n",
        "# Evaluate the best model on the validation set\n",
        "accuracy, precision, recall, f1 = performance(best_model, X_val, y_val)\n",
        "\n",
        "# Print the performance metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Qgs5Sz08dDg",
        "outputId": "8ac98f26-ecca-4d38-89da-0617cc4f3b16"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6243213897937026\n",
            "Precision: 0.6078431372549019\n",
            "Recall: 0.31794871794871793\n",
            "F1-score: 0.4175084175084175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation\n",
        "\n",
        "https://scikit-learn.org/stable/modules/model_evaluation.html"
      ],
      "metadata": {
        "id": "mAssSW_I0GvA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used the scoring metrics as outputs for the above implementations."
      ],
      "metadata": {
        "id": "DUOjs5U4CS_U"
      }
    }
  ]
}